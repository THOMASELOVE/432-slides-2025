---
title: "432 Class 12"
author: Thomas E. Love, Ph.D.
date: "2025-02-20"
format:
  revealjs: 
    theme: simple
    embed-resources: true
    self-contained: true
    slide-number: true
    footnotes-hover: true
    preview-links: auto
    date-format: iso
    logo: 432-2025-pic.png
    footer: "432 Class 12 | 2025-02-20 | <https://thomaselove.github.io/432-2025/>"
---


## Today's R Setup

```{r}
#| echo: true
#| message: false
knitr::opts_chunk$set(comment = NA)

library(janitor)
library(naniar)
library(broom)
library(gt)
library(gtsummary)
library(mosaic)
library(here)       # introduced today
library(conflicted) # introduced today
library(tableone)   # building Table One
library(survey)     # survey-specific tools for weighting
library(nhanesA)    # data source
library(easystats)
library(tidyverse)

theme_set(theme_bw()) 
conflicts_prefer(dplyr::filter(), base::max(), base::sum(), base::mean())
```

## Today's Agenda

1. The **conflicted** package
2. The **here** package
3. Building Table One
4. Working with Survey Weights

## What does the here package do?

The **here** package creates paths relative to the top-level directory. The package displays the top-level of the current project on load or any time you call `here()`.

```{r}
#| echo: true
here()
```

```{r}
#| echo: true
here("c12", "data", "bradley.csv")
```

or

```{r}
#| echo: true
here("c12/data/bradley.csv")
```


## The here package!

![](c12/figures/here.png)

## More on the here package and related issues

- [Jenny Bryan on the here package](https://github.com/jennybc/here_here)

- here package details are available at <https://here.r-lib.org/index.html>

- [Workflow: Scripts and Projects](https://r4ds.hadley.nz/workflow-scripts.html) from R for Data Science

## The conflicted package

<https://conflicted.r-lib.org/>

- The goal of conflicted is to provide an alternative conflict resolution strategy. R’s default conflict resolution system gives precedence to the most recently loaded package. This can make it hard to detect conflicts, particularly when introduced by an update to an existing package. conflicted takes a different approach, making every conflict an error and forcing you to choose which function to use.

## Conflict Resolution here

In the package setup today, I used the following code to resolve errors that came up in these slides:

```
conflicts_prefer(dplyr::filter(), base::max(), base::sum(), base::mean())
```

- That was the complete set of conflicts I had to resolve to get the slides to run.
- As it turns out, though, there are lots of other conflicts that didn't crop up in building these slides, because the relevant conflict never emerged...

## What else does conflicted do?

```{r}
#| echo: true
#| warning: true

conflict_scout()
```

# Building a Table One

## An Original Clinical Investigation

![](c12/figures/bradley_title.png)

[Link to Source](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2720923)

## Part of Bradley et al.'s Table 1

![](c12/figures/bradley_table1.png)

## Table Creation Instructions, JAMA: [linked here](https://jama.jamanetwork.com/data/ifora-forms/jama/tablecreationinst.pdf)

![](c12/figures/jama_table_instructions.png)

## A Data Set {.smaller}

The `bradley.csv` data set is simulated, but consists of 1,374 observations (687 Cases and 687 Controls) containing:

- a subject identification code, in `subject`
- `status` (case or control)
- age (in years)
- sex (Male or Female)
- race/ethnicity (white or non-white)
- married (1 = yes or 0 = no)
- location (ICU, bed, other)

The `bradley.csv` data closely match the summary statistics provided in Table 1 of the Bradley et al. article. Our job is to recreate that part of Table 1, as best as we can.

## The `bradley.csv` data (first 5 rows)

- The `bradley_sim.md` file on our web site shows you how I simulated the data.

![](c12/figures/bradley_csv.png)

## To "Live" Coding

On our web site (Data and Code + Class 12 materials)

- In the `data` folder:
    - `bradley.csv` data file
- `bradley_table1.qmd` Quarto script
- `bradley_table1.md` Results of running Quarto
- `bradley_table1_result.csv` is the table generated by that Quarto script

# To The "Live Code" at <https://rpubs.com/TELOVE/bradley-table1-432>

## Opening `bradley_table1_result.csv` in Excel

![](c12/figures/bradley_table1_result.png)

## Learning More About Table 1

Chapter 18 of the Course Notes covers two larger examples, and more details, like...

- specifying factors, and re-ordering them when necessary
- using non-normal summaries or exact categorical tests
- dealing with warning messages and with missing data
- producing Table 1 in R so you can cut and paste it into Excel or Word

and Lab 5 asks you to do this with a familiar data set.

# Incorporating survey weights (an introduction)

## What are survey weights?

In many surveys, each sampled subject is assigned a weight that is equivalent to the reciprocal of his/her probability of selection into the sample.

$$
\mbox{Sample Subject's Weight} = \frac{1}{Prob(selection)}
$$

but more sophisticated sampling designs require more complex weighting schemes. Usually these are published as part of the survey data.

I'll demonstrate part of the `survey` package today.

## An NHANES Example

Let's use the NHANES 2013-14 data and pull in both the demographics (`DEMO_H`) and total cholesterol (`TCHOL_H`) databases.

```{r}
#| echo: true
demo_raw <- nhanes('DEMO_H', translated = FALSE)
tchol_raw <- nhanes('TCHOL_H', translated = FALSE)
```

Detailed descriptions available at

- <https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/DEMO_H.htm>
- <https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/TCHOL_H.htm>

## Weighting in NHANES {.smaller}

Weights for each sampled person in NHANES account for the complex survey design. The weight describes the number of people in the population represented by the sampled person, and is created in three steps:

1. the base weight is computed, which accounts for the unequal probabilities of selection given that some demographic groups were over-sampled;
2. adjustments are made for non-response; and
3. post-stratification adjustments are made to match estimates of the U.S. civilian non-institutionalized population available from the Census Bureau.

Source: <https://wwwn.cdc.gov/nchs/nhanes/tutorials/Module3.aspx>


## Weights in our NHANES data

The `DEMO` file contains two kinds of sampling weights:

- the interview weight (`WTINT2yr`), and
- the MEC exam weight (`WTMEC2yr`)

NHANES also provides several weights for subsamples. In NHANES, we identify the variable of interest that was collected on the smallest number of respondents. The sample weight that applies to that variable is the appropriate one to use. In our first case, we will study total cholesterol and use the weights from the MEC exam.

## What Variables Do We Need? {.smaller}

- `SEQN` = subject identifying code
- `RIAGENDR` = sex (1 = M, 2 = F)
- `RIDAGEYR` = age (in years at screening, topcode at 80)
- `DMQMILIZ` = served active duty in US Armed Forces (yes/no)
- `RIDSTATR` = 2 if subject took both interview and MEC exam
- `WTMEC2YR` - Full sample 2 year MEC exam weight
- `LBXTC` = Total Cholesterol (mg/dl) - this is our outcome

The first 5 are in `DEMO_H`, and the first and last are in `TCHOL_H`.

## Merge the `DEMO` and `TCHOL` files

```{r}
#| echo: true

dim(demo_raw)
dim(tchol_raw)

joined_df <- inner_join(demo_raw, tchol_raw, by = c("SEQN"))

dim(joined_df)
```

## Create and save a small analytic tibble

```{r}
#| echo: true

nh1314 <- joined_df |> # has n = 8291
    tibble() |>
    filter(complete.cases(LBXTC)) |> # now n = 7624
    filter(RIDSTATR == 2) |> # still 7624
    filter(RIDAGEYR > 19 & RIDAGEYR < 40) |> # now n = 1802
    filter(DMQMILIZ < 3) |> # drop 7 = refused, n = 1801
    mutate(FEMALE = RIAGENDR - 1,
           AGE = RIDAGEYR,
           US_MIL = ifelse(DMQMILIZ == 1, 1, 0),
           WT_EX = WTMEC2YR,
           TOTCHOL = LBXTC) |>
    select(SEQN, FEMALE, AGE, TOTCHOL, US_MIL, WT_EX)

write_rds(nh1314, here("c12/data/nh1314.Rds"))
```

- The nh1314.Rds file is on our 432-data page if you need it.

## `nh1314` analytic sample

```{r}
#| echo: TRUE

nh1314 |> select(AGE, TOTCHOL, WT_EX) |> summary()

nh1314 |> tabyl(FEMALE, US_MIL) |> 
  adorn_totals(where = c("row", "col")) |> adorn_title()
```

## Formatting `df_stats` with `gt()`

```{r}
#| echo: true
df_stats(~ AGE + TOTCHOL, data = nh1314) |>
  mutate(across(mean:sd, ~ round_half_up(.x, 2))) |> 
  gt() |> tab_options(table.font.size = 20) |>
  tab_header(title = "Approach A", 
             subtitle = "Data from nh1314 sample, unadjusted")
```

## Formatting `df_stats` with `gt()`

```{r}
#| echo: true
df_stats(~ AGE + TOTCHOL, data = nh1314) |>
  gt() |> fmt_number(columns = mean:sd, decimals = 2) |>
  tab_options(table.font.size = 20) |>
  tab_header(title = "Approach B", 
             subtitle = "Data from nh1314 sample, unadjusted")
```

## Our `nh1314` analytic sample: Weights

Each weight represents the number of people exemplified by that subject.

```{r}
#| echo: true
favstats(~ WT_EX, data = nh1314) |>
  rename(na = missing) |> gt() |>
  tab_options(table.font.size = 20)
```

## Describing `nh1314` (unweighted)

- using `tbl_summary()` from the **gtsummary** package. See <https://www.danieldsjoberg.com/gtsummary/> for more options.

```{r}
#| echo: true

table1 <- nh1314 |>
  tbl_summary(include = -SEQN)

table1
```



## Create `nh_design` survey design

```{r}
#| echo: true
nh_design <- 
    svydesign(
        id = ~ SEQN,
        weights = ~ WT_EX,
        data = nh1314) 

nh_design <- update( nh_design, one = 1) 

## this one = 1 business will help us count

nh_design
```

## Unweighted Counts

### Overall

```{r}
#| echo: true

sum(weights(nh_design, "sampling") != 0)
```

### By Groups

```{r}
#| echo: true
svyby( ~ one, ~ FEMALE, nh_design, unwtd.count)
svyby( ~ one, ~ FEMALE + US_MIL, nh_design, unwtd.count)
```

## Weighted Counts

```{r}
#| echo: true

svytotal( ~ one, nh_design )
```

### By Groups

```{r}
#| echo: true

svyby( ~ one, ~ FEMALE, nh_design, svytotal)
svyby( ~ one, ~ FEMALE * US_MIL, nh_design, svytotal)
```

## Use survey design for weighted means

What is the mean of total cholesterol, overall and in groups?

```{r}
#| echo: true

svymean( ~ TOTCHOL, nh_design, na.rm = TRUE)

svyby(~ TOTCHOL, ~ FEMALE, nh_design, svymean, na.rm = TRUE)

svyby(~ TOTCHOL, ~ FEMALE + US_MIL, nh_design, svymean, na.rm = TRUE)
```

## Unweighted Summaries of TOTCHOL

```{r}
#| echo: true

favstats(~ TOTCHOL, data = nh1314) |> 
  mutate(se = sd / sqrt(n)) |>
  gt() |> fmt_number(columns = c(mean, sd, se), decimals = 3) |>
  tab_options(table.font.size = 20)
```

```{r}
#| echo: true

nh1314 |> group_by(FEMALE, US_MIL) |>
  summarise(n = n(), mean = mean(TOTCHOL), se = sd(TOTCHOL)/sqrt(n)) |> gt()
```


## Survey-Weighted Measures of uncertainty

Mean of total cholesterol within groups with 90% CI?

```{r}
#| echo: true

grouped_result <- svyby(~ TOTCHOL, ~ FEMALE + US_MIL, 
                        nh_design, svymean, na.rm = TRUE)
coef(grouped_result)
confint(grouped_result, level = 0.90)
```

- Get standard errors with `se(grouped_result)`, too.

## Store estimated means in `res`

```{r}
#| echo: true
res <- tibble(
  type = rep(c("Unweighted", "Survey-Weighted"),4),
  female = c(rep("Female", 4), rep("Male", 4)),
  us_mil = rep(c("Military", "Military", "Not Military", "Not Military"), 2),
  MEAN = c(169.5, 164.198, 179.706, 180.025, 
           187.111, 186.697, 182.220, 182.357))
res |> gt()
```

## Estimated Means, plotted

```{r}
#| echo: true
ggplot(res, aes(x = female, y = MEAN, col = type)) +
  geom_point(size = 4) +
  facet_wrap(~ us_mil)
```

# Building Models and Survey Weights

## Modeling `TOTCHOL` in `nh1314`

First, we'll ignore weighting, and fit a model with main effects of all three predictors (`mod1`), then a model (`mod2`) which incorporates an interaction of FEMALE and US_MIL.

```{r}
#| echo: true
mod1 <- lm(TOTCHOL ~ AGE + FEMALE + US_MIL, data = nh1314)

mod2 <- lm(TOTCHOL ~ AGE + FEMALE * US_MIL, data = nh1314)
```

The interaction term means that the effect of FEMALE on TOTCHOL depends on the US_MIL status.

## `mod1`, unweighted

```{r}
#| echo: true
tidy(mod1, conf.int = TRUE, conf.level = 0.90) |>
  select(-statistic) |> gt() |> tab_options(table.font.size = 20)
```

```{r}
#| echo: true
glance(mod1) |> select(r2 = r.squared, adjr2 = adj.r.squared, AIC, BIC,
    sigma, nobs, df) |> gt() |> tab_options(table.font.size = 20)
```

## `mod1`, unweighted

- Now using functions from the easystats framework...

```{r}
#| echo: true
model_parameters(mod1, pretty_names = FALSE, ci = 0.90)
model_performance(mod1)
n_obs(mod1)
```


## `mod1` Residuals (first 2 plots)

```{r}
#| echo: true
check_model(mod1, check = c("linearity", "homogeneity"))
```

## `mod1` Residuals (plots 3-4)

```{r}
#| echo: true
check_model(mod1, detrend = FALSE, check = c("outliers", "qq"))
```

## `mod1` prediction check

```{r}
#| echo: true
check_model(mod1, check = "pp_check")
```


## `mod2`, unweighted

```{r}
#| echo: true
tidy(mod2, conf.int = TRUE, conf.level = 0.90) |>
  select(-statistic) |> gt() |> tab_options(table.font.size = 20)
```

```{r}
#| echo: true
glance(mod2) |> 
  select(r2 = r.squared, adjr2 = adj.r.squared, AIC, BIC, sigma, 
         nobs, df) |> gt() |> tab_options(table.font.size = 20)
```

## `mod2` Residuals (first 2 plots)

```{r}
#| echo: true
check_model(mod2, check = c("linearity", "homogeneity"))
```

## `mod2` Residuals (plots 3-4)

```{r}
#| echo: true
check_model(mod2, detrend = FALSE, check = c("outliers", "qq"))
```

## `mod2` prediction check

```{r}
#| echo: true
check_model(mod2, check = "pp_check")
```

## Survey-weighted models via `svyglm`

Again, we'll run two models, first without and second with an interaction term between `FEMALE` and `US_MIL`.

```{r}
#| echo: true

glm1_results <- svyglm(TOTCHOL ~ AGE + FEMALE + US_MIL, 
    nh_design, family = gaussian())
```

```{r}
#| echo: true

glm2_results <- svyglm(TOTCHOL ~ AGE + FEMALE * US_MIL, 
    nh_design, family = gaussian())
```

Gaussian family used to generate linear regressions here.

## Weighted Model 1

```{r}
#| echo: true

tidy(glm1_results, conf.int = TRUE, conf.level = 0.90) |>
  select(-statistic) |> gt() |> tab_options(table.font.size = 20)
```

```{r}
#| echo: true

glance(glm1_results) |> select(nobs, AIC, BIC, everything()) |> 
  gt() |> tab_options(table.font.size = 20)
```

## Weighted Model 2

```{r}
#| echo: true

tidy(glm2_results, conf.int = TRUE, conf.level = 0.90) |>
  select(-statistic) |> gt() |> tab_options(table.font.size = 20)
```

```{r}
#| echo: true

glance(glm2_results) |> select(nobs, AIC, BIC, everything()) |>
  gt() |> tab_options(table.font.size = 20)
```

## `glm1_results` Residuals (first 2 plots)

```{r}
#| echo: true
check_model(glm1_results, check = c("linearity", "homogeneity"))
```

## `glm1_results` Residuals (plots 3-4)

```{r}
#| echo: true
check_model(glm1_results, detrend = FALSE, check = c("outliers", "qq"))
```

## `glm1_results` prediction check

```{r}
#| echo: true
check_model(glm1_results, check = "pp_check")
```

## `glm2_results` Residuals (first 2 plots)

```{r}
#| echo: true
check_model(glm2_results, check = c("linearity", "homogeneity"))
```

## `glm2_results` Residuals (plots 3-4)

```{r}
#| echo: true
check_model(glm2_results, detrend = FALSE, check = c("outliers", "qq"))
```

## `glm2_results` prediction check

```{r}
#| echo: true
check_model(glm2_results, check = "pp_check")
```

## See Lab 5 Question 2

Using the `nh_3143` data you've used before, ...

> Estimate the percentage of the US non-institutionalized adult population within the ages of 30-59 who have smoked at least 100 cigarettes in their life that would describe their General Health as either “Excellent” or “Very Good”.

and you'll do this without and then with sampling weights; due on Wednesday.

# A More Complete Weighted NHANES Analysis 

## New Question, New Data

Key Source: <https://wwwn.cdc.gov/nchs/data/tutorials/DB303_Fig1_R.R>

Now, we are looking at the percentage of persons aged 20 and over with depression, by age and sex, in the US in 2013-2016. Pull in data using `nhanesA`...

```{r}
#| echo: true

DEMO_H <- nhanes('DEMO_H', translated = FALSE) |> 
  select(SEQN, RIAGENDR, RIDAGEYR, SDMVSTRA, SDMVPSU, WTMEC2YR)
DEMO_I <- nhanes('DEMO_I', translated = FALSE) |>
  select(SEQN, RIAGENDR, RIDAGEYR, SDMVSTRA, SDMVPSU, WTMEC2YR)
DEMO <- bind_rows(DEMO_H, DEMO_I) 
DPQ_H <- nhanes('DPQ_H', translated = FALSE) 
DPQ_I <- nhanes('DPQ_I', translated = FALSE) 
DPQ <- bind_rows(DPQ_H, DPQ_I) 
```

## Merge DEMO & DPQ, create derived variables

```{r}
#| echo: true
nhanes2 <- left_join(DEMO, DPQ, by = "SEQN") |> tibble() |>
  # Set 7=Refused and 9=Don't Know To NA 
  mutate(across(.cols = DPQ010:DPQ090, 
                ~ ifelse(. >=7, NA, .))) %>%
  mutate(one = 1,
         PHQ9_score = rowSums(select(. , DPQ010:DPQ090)),
         Depression = ifelse(PHQ9_score >= 10, 100, 0),
         Sex = factor(RIAGENDR, labels = c("M", "F")),
         Age_group = cut(RIDAGEYR, 
            breaks = c(-Inf, 19, 39, 59, Inf),
            labels = c("Under 20", "20-39", "40-59", "60+")),
         WTMEC4YR = WTMEC2YR/2,
         inAnalysis = (RIDAGEYR >= 20 & !is.na(PHQ9_score))) |>
  select(-starts_with("DPQ"))

write_rds(nhanes2, here("c12/data/nhanes_class12_data2.Rds"))
```

- nhanes_class12_data2.Rds file is on our 432-data page.

## Define The Survey Design

Here's the survey design for the overall data set:

```{r}
#| echo: true
NH_des_all <- svydesign(data = nhanes2, id = ~ SDMVPSU, 
  strata = ~ SDMVSTRA, weights = ~ WTMEC4YR, nest = TRUE)

dim(NH_des_all)
```

Here's the survey design object for the subset of interest: adults aged 20 and over with a valid PHQ-9 depression score:

```{r}
#| echo: true

NH_des_2 <- NH_des_all |> subset(inAnalysis)

dim(NH_des_2)
```

## Define a function to call svymean and unweighted count

```{r}
#| echo: true

ourSummary <- function(varformula, byformula, design){
  # Get mean, stderr, and unweighted sample size
  c <- svyby(varformula, byformula, design, unwtd.count ) 
  p <- svyby(varformula, byformula, design, svymean ) 
  outSum <- left_join(select(c,-se), p) 
  outSum
}
```

### Estimate overall prevalence of depression

```{r}
#| echo: true
ourSummary(~ Depression, ~ one, NH_des_2)
```

## Estimate prevalence of depression in various strata

```{r}
#| echo: true

## By sex
ourSummary(~ Depression, ~ Sex, NH_des_2)
## By age
ourSummary(~ Depression, ~ Age_group, NH_des_2)
```

## Estimate prevalence of depression by Age and Sex

```{r}
#| echo: true

## By sex and age
ourSummary(~ Depression, ~ Sex + Age_group, NH_des_2)
```

## Compare Prevalence between Male and Female

Across all age groups:

```{r}
#| echo: true
svyttest(Depression ~ Sex, NH_des_2)
```

## Compare Prevalence between Male and Female

In people ages 40-59:

```{r}
#| echo: true
svyttest(Depression ~ Sex, subset(NH_des_2, Age_group == "40-59"))
```

## Differences by Age Group, among Adults

```{r}
#| echo: true

svyttest(Depression ~ Age_group, subset(NH_des_2, 
                  Age_group=="20-39" | Age_group=="40-59"))
```
