---
title: "432 Class 03"
author: Thomas E. Love, Ph.D.
date: "2025-01-21"
format:
  revealjs: 
    theme: simple
    embed-resources: true
    self-contained: true
    slide-number: true
    footnotes-hover: true
    preview-links: auto
    date-format: iso
    logo: 432-2025-pic.png
    footer: "432 Class 03 | 2025-01-21 | <https://thomaselove.github.io/432-2025/>"
---

## Today's Agenda

- Fitting linear regression models with `lm`
    - ANOVA: Incorporating an interaction between factors
    - ANCOVA: Incorporating a quantitative covariate
- Regression Diagnostics via `check_model()`
- Validating / evaluating results with `yardstick`

### Appendix (see @sec-appendix)

How the `smt_im` data were created from `smart_ohio.csv`

## Today's R Setup

```{r}
#| echo: true
#| message: false
knitr::opts_chunk$set(comment = NA)

library(janitor)
library(naniar)
library(broom)
library(car)
library(gt)
library(mosaic)         ## for df_stats and favstats
library(mice)           ## imputation of missing data
library(patchwork)       
library(rsample)        ## data splitting
library(easystats)
library(tidyverse)      

theme_set(theme_lucid()) 
```

# The `smt_im` data

## The `smt_im` data

- 894 subjects in Cleveland-Elyria with `bmi` and no history of diabetes (missing values singly imputed: assume MAR)
- All subjects have `hx_diabetes` (all 0), and are located in the `MMSA` labeled Cleveland-Elyria.
- See [Course Notes Chapter on BRFSS SMART data](https://thomaselove.github.io/432-notes/06-smart.html) for variable details
- Appendix provides details on data development.

## The Five Variables We'll Use Today
 
9 variables in the data but we'll use only these 5 today.

Variable | Description
:----: | --------------------------------------
`ID` | subject identifying code
`bmi` | (outcome) Body-Mass index in $kg/m^2$.
`exerany` | any exercise in past month: 1 = yes, 0 = no
`health` | self-reported overall health (5 levels)
`fruit_day` | average fruit servings consumed per day

## Data Load

```{r}
#| echo: true
smt_im <- read_rds("c03/data/smt_im.Rds") |>
  select(ID, bmi, exerany, health, fruit_day, everything())

smt_im
```

## Checking our Data

Are there any missing values?

```{r}
#| echo: true

smt_im |> n_miss() 
```

Does each row have a unique `ID` value?

```{r}
#| echo: true
identical(nrow(smt_im), n_distinct(smt_im$ID)) 
```

## Range and Level Checks?

```{r}
#| echo: true
data_codebook(smt_im |> select(bmi, exerany, health, fruit_day)) 
```

## Our outcome, `bmi`

```{r}
#| echo: true
ggplot(smt_im, aes(x = bmi)) +
  geom_histogram(binwidth = 2, col = "azure", fill = "coral")
```

## Key predictors: `exerany`, `health`

```{r}
#| echo: true

smt_im |> tabyl(exerany, health) |> 
  adorn_totals(where = c("row", "col")) |>
  gt() |> tab_options(table.font.size = 28)
```

Here, it doesn't matter much whether we store the 1/0 in `exerany` as numeric or as a two-level factor in R. For binary variables, sometimes the numeric version will be more useful and sometimes a factor will be more useful.

## Our covariate, `fruit_day`

We are mostly interested in whether accounting for the quantitative covariate `fruit_day` changes the modeled association of our key predictors with `bmi`. 

- Sometimes we center such a covariate (subtracting its mean.)

```{r}
#| echo: true
smt_im <- smt_im |>
  mutate(fruit_c = fruit_day - mean(fruit_day))
```

- Why? So that we can easily plug in the covariate's mean (which will now be 0) when making predictions.

## Did we center `fruit_day` properly?

Here's a little "sanity check":

```{r}
#| echo: true
df_stats(~ fruit_day + fruit_c, data = smt_im) |> gt() |>
  fmt_number(columns = min:sd, decimals = 3) |>
  tab_options(table.font.size = 24)
```

The `df_stats()` function comes from the `mosaic` package, and can be used to apply `favstats()` to multiple variables at once.

## Modeling Plan

1. Split `smt_im` into training and testing samples.
2. Predict `bmi` using `exer_any` and `health`
    - (`fit1`): without an interaction between the predictors
    - (`fit2`): and then with an interaction term
3. (`fit3`): Then add in our (centered) covariate, `fruit_c`.
4. (`fit4`): Use a quadratic polynomial in `fruit_c`.
5. Assess all four models in training and testing samples. 

## Splitting the Sample

We'll partition our data set using some tools from the `rsample` package, into:

- a training sample containing 75% of the data
- a testing sample containing the remaining 25%

```{r}
#| echo: true
set.seed(432)    ## for future replication

smt_im_split <- initial_split(smt_im, prop = 3/4)

train_smt_im <- training(smt_im_split)
test_smt_im <- testing(smt_im_split)

c(nrow(smt_im), nrow(train_smt_im), nrow(test_smt_im))
```

# Building Our Four Models

## Modeling Plan

- Predict `bmi` using `exer_any` and `health`
    - (`fit1`): without an interaction between the predictors
    - (`fit2`): and then with an interaction term
- (`fit3`): Then add in our (centered) covariate, `fruit_c`.
- (`fit4`): Use a quadratic polynomial in `fruit_c`.

## Tukey's ladder of power transformations

$\lambda$ | 2 | 1 | 0.5 | 0 | -0.5 | -1 | -2
--------- | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
Transform | $y^2$ | $y$ | $\sqrt{y}$ | $log(y)$ | $\frac{1}{\sqrt{y}}$ | $\frac{1}{y}$ | $\frac{1}{y^2}$

- Used in combination with a Box-Cox plot from `car`
- Requires the $y$ variable to be **strictly positive**.
    - If desirable, you can add any constant to $y$ or multiply $y$ by any constant, before or after the transformation.
- Be sure you can back out of the transformation:
- $exp(log(y)) = y$, $\sqrt{y^2} = y$, $1/\frac{1}{y} = y$, $[1 / (\frac{1}{\sqrt{y}})]^2 = y$

## Consider transforming `bmi`?

```{r}
#| echo: true

m0 <- lm(bmi ~ exerany + health + fruit_c, data = train_smt_im)
boxCox(m0)
```


## Should we transform `bmi`? (n = 670)

```{r}
#| echo: true
#| output-location: slide

p1a <- ggplot(train_smt_im, aes(x = bmi)) + 
    geom_histogram(col = "navy", fill = "cyan", bins = 20)

p1b <- ggplot(train_smt_im, aes(x = bmi, y = "bmi")) + 
    geom_boxplot(col = "navy", fill = "cyan") + labs(y = "") +
    stat_summary(geom = "point", col = "red", fun = mean, size = 3)

p2a <- ggplot(train_smt_im, aes(x = 1/sqrt(bmi))) + 
    geom_histogram(col = "navy", fill = "gold", bins = 20)

p2b <- ggplot(train_smt_im, aes(x = 1/sqrt(bmi), y = "1/sqrt(bmi)")) +
    geom_boxplot(col = "navy", fill = "gold") + labs(y = "") +
    stat_summary(geom = "point", col = "red", fun = mean, size = 3)

p3a <- ggplot(train_smt_im, aes(x = 1/bmi)) + 
    geom_histogram(col = "navy", fill = "green", bins = 20)

p3b <- ggplot(train_smt_im, aes(x = 1/bmi, y = "1/bmi")) + 
    geom_boxplot(col = "navy", fill = "green") + labs(y = "") +
    stat_summary(geom = "point", col = "red", fun = mean, size = 3)

(p1a + p1b) / (p2a + p2b) / (p3a + p3b)
```

## Re-scaling the transformation

To ease interpretation of coefficients, I sometimes scale an outcome transformation so that its values fall in (10, 100), rather than between 0 and 1.

```{r}
#| echo: true
bind_rows( favstats(~ 1/sqrt(bmi), data = train_smt_im),
           favstats(~ 100/sqrt(bmi), data = train_smt_im)) |>
  mutate(outcome = c("1/sqrt(bmi)", "100/sqrt(bmi)")) |> 
  relocate(outcome) |>
  gt() |> fmt_number(columns = min:sd, decimals = 3) |> 
  tab_options(table.font.size = 24)
```

## Shape doesn't change

```{r}
p2 <- ggplot(train_smt_im, aes(x = 1/sqrt(bmi))) + 
  geom_histogram(col = "navy", fill = "green", bins = 20) +
  labs(title = "1/sqrt(BMI)")

p3 <- ggplot(train_smt_im, aes(x = 100/sqrt(bmi))) +
  geom_histogram(col = "navy", fill = "green", bins = 20) + 
  labs(title = "100/sqrt(BMI)")

p2 / p3
```

## Means by `exerany` and `health`

```{r}
#| echo: true
summaries_1 <- train_smt_im |>
    group_by(exerany, health) |>
    summarise(n = n(), mean = mean(100/sqrt(bmi)), 
              stdev = sd(100/sqrt(bmi)))
summaries_1 
```

## Code for Interaction Plot 

```{r}
#| echo: true
#| output-location: slide
ggplot(summaries_1, aes(x = health, y = mean, col = factor(exerany))) +
  geom_line(aes(group = factor(exerany)), linewidth = 2) +
  scale_color_viridis_d(option = "C", end = 0.5) +
  labs(title = "Observed Means of 100/sqrt(BMI)",
       subtitle = "by Exercise and Overall Health")
```

- Note the use of `factor` here since the `exerany` variable is in fact numeric, although it only takes the values 1 and 0.
    - Sometimes it's helpful to treat 1/0 as a factor, and sometimes not.
- Where is the evidence of serious non-parallelism (if any) in the plot (see next slide) that results from this code?

# Fitting a Two-Way ANOVA model for $100/\sqrt{BMI}$

## Create our transformed outcome

We'll want to do this in both our training and test samples.

```{r}
#| echo: true

train_smt_im <- train_smt_im |> mutate(bmi_tr = 100 / sqrt(bmi))

test_smt_im <- test_smt_im |> mutate(bmi_tr = 100 / sqrt(bmi))
```

## Model `fit1` without interaction

```{r}
#| echo: true
fit1 <- lm(bmi_tr ~ exerany + health, data = train_smt_im)
```

Using the `tidy()` function from `broom`:

```{r}
#| echo: true
tidy(fit1, conf.int = TRUE, conf.level = 0.90) |> 
  gt() |> fmt_number(columns = estimate:conf.high, decimals = 3) |>
  tab_options(table.font.size = 24)
```

## Model Parameters for `fit1`

```{r}
#| echo: true
model_parameters(fit1, ci = 0.90) 
```

## Model Parameters for `fit1` (with `gt()`)

Reformatting with `gt()`...

```{r}
#| echo: true
model_parameters(fit1, ci = 0.90) |> 
  gt() |> fmt_number(columns = -c(CI, df_error), decimals = 3) |>
  tab_options(table.font.size = 24)
```

---

::: {.callout-note title="The fit1 equation"}
`fit1`: $100/\sqrt{bmi}$ = 19.31 + .57 `exerany` - .20 (VG) - .96 (G) - .98 (F) - 1.08 (P)
:::

Name | `exerany` | `health` | predicted $100/\sqrt{bmi}$
-------- | :------: | :------: | ---------:
Harry | 0 | Excellent | 19.31
Sally   | 1 | Excellent | 19.31 + .57 = 19.88
Billy | 0 | Fair | 19.31 - .98 = 18.33
Meg | 1 | Fair | 19.31 + .57 - .98 = 18.90

- Effect of `exerany` on $100/\sqrt{bmi}$?
- Effect of `health` = Fair instead of Excellent?

## How well does `fit1` fit the training data?

```{r}
#| echo: true

n_obs(fit1)
model_performance(fit1)
```

```{r}
#| echo: true
glance(fit1) |> 
    select(r.squared, adj.r.squared, sigma, nobs, 
           df, df.residual, AIC, BIC) |> 
  gt() |> fmt_number(columns = r.squared:sigma, decimals = 3) |>
  fmt_number(columns = AIC:BIC, decimals = 1) |>
  tab_options(table.font.size = 24)
```

## Tidied ANOVA for `fit1`

```{r}
#| echo: true
tidy(anova(fit1)) |> gt() |> 
  fmt_number(columns = sumsq:statistic, decimals = 2) |>
  fmt_number(columns = p.value, decimals = 4) |>
  tab_options(table.font.size = 24)
```


## Model Checks

We'll be checking assumptions related to:

- linearity
- homoscedasticity (constant variance)
- influential observations (outliers, leverage and influence)
- whether the residuals follow a Normal distribution
- collinearity (variance inflation factor)
- and a posterior predictive check of our predictions

## My slides and `check_model()`

When building a regular HTML file, I would just use:

```{r}
#| echo: true
#| eval: false

check_model(fit1, detrend = FALSE)
```

with `#| fig-height: 9` at the start of the code chunk so that the plots are taller than the default height (thus easier to read) but I will split out the plots for slides.

:::{.callout-note title="Problem with `check_model()`"}

- The problem with `check_model()` (particularly on Macs) now seems to be rectified. Update your packages (for instance, to `performance` version 0.13.0 or later) if you haven't yet.

:::

## Checking model `fit1` (*n* = 670)

```{r}
#| echo: true
check_model(fit1, check = c("linearity", "homogeneity"))
```

## Checking model `fit1` (*n* = 670)

```{r}
#| echo: true
check_model(fit1, check = c("outliers", "qq"), detrend = FALSE)
```

## Checking model `fit1` (*n* = 670)

```{r}
#| echo: true
check_model(fit1, check = c("pp_check", "vif"))
```

# Fitting ANOVA model `fit2` including interaction

## Adding the interaction term to `fit1`

```{r}
#| echo: true
fit2 <- lm(bmi_tr ~ exerany * health, data = train_smt_im)
```

- How do our models compare on fit to the training data?

```{r}
#| echo: true
bind_rows(glance(fit1), glance(fit2)) |>
  mutate(mod = c("fit1", "fit2")) |>
  select(mod, r.sq = r.squared, adj.r.sq = adj.r.squared, 
         sigma, nobs, df, df.res = df.residual, AIC, BIC) |> 
  gt() |> fmt_number(columns = r.sq:sigma, decimals = 3) |>
  fmt_number(columns = AIC:BIC, decimals = 1) |>
  tab_options(table.font.size = 24)
```

## ANOVA for the `fit2` model

```{r}
#| echo: true
tidy(anova(fit2)) |> gt() |> 
  fmt_number(columns = sumsq:statistic, decimals = 2) |>
  fmt_number(columns = p.value, decimals = 4) |>
  tab_options(table.font.size = 20)
```

## ANOVA test comparing `fit1` to `fit2`

```{r}
#| echo: true
anova(fit1, fit2)
```

## `fit2` coefficients

```{r}
#| echo: true
tidy(fit2, conf.int = TRUE, conf.level = 0.90) |>
  gt() |> fmt_number(columns = estimate:conf.high, decimals = 3) |>
  tab_options(table.font.size = 20)
```

## Interpreting the `fit2` model

Name | `exerany` | `health` | predicted $100/\sqrt{bmi}$
-------- | :------: | :------: | ---------:
Harry | 0 | Excellent | 19.19
Sally   | 1 | Excellent | 19.19 + .72 = 19.91
Billy | 0 | Fair | 19.19 - 1.73 = 17.46
Meg | 1 | Fair | 19.19 + .72 - 1.73 + 1.29 = 19.47

- How do we interpret effect sizes here? **It depends**...

## Interpreting the `fit2` model

- Effect of `exerany` on predicted $100/\sqrt{bmi}$?
    - If `health` = Excellent, effect is +0.72
    - If `health` = Fair, effect is (0.72 + 1.29) = +2.01
- Effect of `health` = Fair instead of Excellent?
    - If `exerany` = 0 (no), effect is -1.73
    - If `exerany` = 1 (yes), effect is (-1.73 + 1.29) = -0.44

## Checking model `fit2` (*n* = 670)

```{r}
#| echo: true
check_model(fit2, check = c("linearity", "homogeneity"))
```

## Checking model `fit2` (*n* = 670)

```{r}
#| echo: true
check_model(fit2, check = c("outliers", "qq"), detrend = FALSE)
```

## Checking model `fit2` (*n* = 670)

```{r}
#| echo: true
check_model(fit2, check = c("pp_check", "vif"))
```

# Incorporating a Covariate into our two-way ANOVA models

## Add `fruit_c` to `fit1`

```{r}
#| echo: true
fit3 <- lm(bmi_tr ~ fruit_c + exerany + health, data = train_smt_im)
```

- How well does this model fit the training data?

```{r}
#| echo: true
bind_rows(glance(fit1), glance(fit3)) |>
  mutate(mod = c("fit1", "fit3")) |>
  select(mod, r.sq = r.squared, adj.r.sq = adj.r.squared, 
         sigma, df, df.res = df.residual, AIC, BIC) |> 
  gt() |> fmt_number(columns = r.sq:sigma, decimals = 3) |>
  fmt_number(columns = AIC:BIC, decimals = 1) |>
  tab_options(table.font.size = 24)
```

## ANOVA for the `fit3` model

```{r}
#| echo: true
tidy(anova(fit3)) |> gt() |> 
  fmt_number(columns = sumsq:statistic, decimals = 2) |>
  fmt_number(columns = p.value, decimals = 4) |>
  tab_options(table.font.size = 24)
```


## `fit3` coefficients

```{r}
#| echo: true
tidy(fit3, conf.int = TRUE, conf.level = 0.90) |>
  gt() |> fmt_number(columns = estimate:conf.high, decimals = 3) |>
  tab_options(table.font.size = 24)
```

## Checking model `fit3` (*n* = 670)

```{r}
#| echo: true
check_model(fit3, detrend = FALSE, check = c("pp_check", "qq"))
```


## Include the interaction term?

```{r}
#| echo: true
fit4 <- lm(bmi_tr ~ fruit_c + exerany * health, 
          data = train_smt_im)
```

### ANOVA for the `fit4` model

```{r}
#| echo: true
tidy(anova(fit4)) |> gt() |> 
  fmt_number(columns = sumsq:statistic, decimals = 2) |>
  fmt_number(columns = p.value, decimals = 4) |>
  tab_options(table.font.size = 20)
```

## `fit4` coefficients

```{r}
#| echo: true
tidy(fit4, conf.int = TRUE, conf.level = 0.90) |>
  gt() |> fmt_number(columns = estimate:conf.high, decimals = 3) |>
  tab_options(table.font.size = 18)
```

## ANOVA: Compare `fit3` & `fit4`

```{r}
#| echo: true
anova(fit3, fit4)
```

## Checking model `fit3` (*n* = 670)

```{r}
#| echo: true
check_model(fit4, detrend = FALSE, check = c("pp_check", "qq"))
```

# Comparing Our Models

## Which of the four models fits best?

In the **training** sample, our model results (note ordering):

```{r}
bind_rows(glance(fit1), glance(fit3), glance(fit2), glance(fit4)) |>
  mutate(mod = c("fit1", "fit3", "fit2", "fit4")) |>
  select(mod, r.sq = r.squared, adj.r.sq = adj.r.squared, 
         sigma, df, df.res = df.residual, AIC, BIC) |> 
  gt() |> fmt_number(columns = r.sq:sigma, decimals = 3) |>
  fmt_number(columns = AIC:BIC, decimals = 1) |>
  tab_options(table.font.size = 20)
```

- Adjusted $R^2$, $\sigma$ and AIC all improve as we move down this table. BIC likes `fit1` and `fit3`.
- The training sample is the data our models have *already seen*, so we should be cautious.

## Comparison Plot: In-Sample Performance

```{r}
#| echo: true

plot(compare_performance(fit1, fit2, fit3, fit4))
```



## What does `augment()` give us?

```{r}
#| echo: true

fit1_test_aug <- augment(fit1, newdata = test_smt_im) 
fit1_test_aug |> select(ID, bmi_tr, bmi, .fitted, .resid, health, exerany) |>
  slice(198:202) |> gt() |> 
  fmt_number(columns = bmi_tr:.resid, decimals = 2) |>
  tab_options(table.font.size = 20)
```

Here, `.fitted` = predicted `bmi_tr` and `.resid` = `bmi_tr` - `.fitted`.

## Back-Transformation of `bmi_tr`

Our models predict `bmi_tr` = $100/\sqrt{bmi}$, but we want to predict `bmi`. How do we convert predicted $100/\sqrt{bmi}$ to predicted `bmi`?

$$
1 / \left(\frac{100}{\sqrt{bmi}}\right) = \sqrt{bmi} / 100, \\
\mbox{so } 100 / \left(\frac{100}{\sqrt{bmi}}\right) = \sqrt{bmi}, \\
\mbox{and so } \left[100 / \left(\frac{100}{\sqrt{bmi}}\right)\right]^2 = bmi
$$

## `augment()` with results for `bmi`

We use $(\frac{100}{.fitted})^2$ for predicted `bmi`, then errors are `bmi_res` = observed `bmi` - predicted `bmi`.

```{r}
#| echo: true
fit1_test_aug <- augment(fit1, newdata = test_smt_im) |> 
  mutate(bmi_fit = (100/.fitted)^2, bmi_res = bmi - bmi_fit)

fit1_test_aug |> select(ID, bmi, bmi_fit, bmi_res, 
      bmi_tr, .fitted, .resid, exerany, health, fruit_c) |>
  slice(5:6) |> gt() |> 
  fmt_number(columns = c(bmi:.resid, fruit_c), decimals = 2) |>
  tab_options(table.font.size = 24)
```


## Augment all four models so far...

```{r}
#| echo: true
fit1_test_aug <- augment(fit1, newdata = test_smt_im) |>
  mutate(bmi_fit = (100/.fitted)^2, bmi_res = bmi - bmi_fit)

fit2_test_aug <- augment(fit2, newdata = test_smt_im) |>
  mutate(bmi_fit = (100/.fitted)^2, bmi_res = bmi - bmi_fit)

fit3_test_aug <- augment(fit3, newdata = test_smt_im) |>
  mutate(bmi_fit = (100/.fitted)^2, bmi_res = bmi - bmi_fit)

fit4_test_aug <- augment(fit4, newdata = test_smt_im) |>
  mutate(bmi_fit = (100/.fitted)^2, bmi_res = bmi - bmi_fit)
```

## Four Key Error Summaries

We'll look at all four of these summaries when we do linear regression, usually.

- Mean absolute prediction error (MAPE)
- Maximum absolute prediction error (Max. Error)
- Square root of mean squared prediction error (RMSPE)
- Squared correlation of observed and predicted `bmi` (validated $R^2$)

## Key Summaries for `fit1`

```{r}
#| echo: true

fit1_esum <- fit1_test_aug |>
  summarise(MAPE = mean(abs(bmi_res)),
            Max_E = max(abs(bmi_res)),
            RMSPE = sqrt(mean(bmi_res^2)),
            Val_R2 = cor(bmi, bmi_fit)^2) |>
  mutate(Model = "fit1")

fit1_esum
```

- I built the key summaries for `fit2`, `fit3` and `fit4` in the same way (included in code, not shown in slides.)

```{r}
fit2_esum <- fit2_test_aug |>
  summarise(MAPE = mean(abs(bmi_res)),
            Max_E = max(abs(bmi_res)),
            RMSPE = sqrt(mean(bmi_res^2)),
            Val_R2 = cor(bmi, bmi_fit)^2) |>
  mutate(Model = "fit2")

fit3_esum <- fit3_test_aug |>
  summarise(MAPE = mean(abs(bmi_res)),
            Max_E = max(abs(bmi_res)),
            RMSPE = sqrt(mean(bmi_res^2)),
            Val_R2 = cor(bmi, bmi_fit)^2) |>
  mutate(Model = "fit3")

fit4_esum <- fit4_test_aug |>
  summarise(MAPE = mean(abs(bmi_res)),
            Max_E = max(abs(bmi_res)),
            RMSPE = sqrt(mean(bmi_res^2)),
            Val_R2 = cor(bmi, bmi_fit)^2) |>
  mutate(Model = "fit4")
```

## Compare Models in Test Sample

```{r}
#| echo: true
bind_rows(fit1_esum, fit2_esum, fit3_esum, fit4_esum) |>
  relocate(Model) |> gt() |> fmt_number(decimals = 3) |>
  tab_options(table.font.size = 24)
```

:::{.callout-note title="Our Four Models"}
- `fit1`: `exerany` and `health` main effects; `fit2`: add interaction
- `fit3`: add `fruit_c` to `fit1`; `fit4`: add `fruit_c` to `fit2`
:::

## Next up...

Basics of logistic regression fitting and evaluation

- What if we have a binary (yes/no or 1/0) outcome?
- Predict "whether or not BMI < 30", rather than BMI?
  - A linear probability model as a first idea
  - Using `glm()` rather than `lm()` to get a logistic model
  - Coefficients as log(odds ratios)
  - Changes in how we measure the model's performance
  - Changes in the assumptions we make

# Appendix {#sec-appendix}

## Creating Today's Data Set

```{r}
#| echo: true
#| message: false
url1 <- "https://raw.githubusercontent.com/THOMASELOVE/432-data/master/data/smart_ohio.csv"

smart_ohio <- read_csv(url1)

smt <- smart_ohio |>
    filter(hx_diabetes == 0, mmsa == "Cleveland-Elyria",
           complete.cases(bmi)) |>
    select(bmi, inc_imp, fruit_day, drinks_wk, 
           female, exerany, genhealth, race_eth, 
           hx_diabetes, mmsa, SEQNO) |>            
    mutate(across(where(is.character), as_factor)) |>
    mutate(ID = as.character(SEQNO - 2017000000)) |>
    relocate(ID)
```

## Codebook for useful `smt` variables (1)

- 894 subjects in Cleveland-Elyria with `bmi` and no history of diabetes

Variable | Description
:----: | --------------------------------------
`bmi` | (outcome) Body-Mass index in $kg/m^2$.
`inc_imp` | income (imputed from grouped values) in $
`fruit_day` | average fruit servings consumed per day
`drinks_wk` | average weekly alcoholic drinks consumed
`female` | sex: 1 = female, 0 = male

## Codebook for useful `smt` variables (2)

- 894 subjects in Cleveland-Elyria without diabetes

Variable | Description
:----: | --------------------------------------
`exerany` | any exercise in past month: 1 = yes, 0 = no
`genhealth` | self-reported overall health (5 levels)
`race_eth` | race and Hispanic/Latinx ethnicity (5 levels)

- plus `ID`, `SEQNO`, `hx_diabetes` (all 0), `MMSA`
- See [Course Notes Chapter 6](https://thomaselove.github.io/432-notes/smart.html) on BRFSS SMART data

## Basic Data Summaries

Available approaches include:

- `data_codebook()` from `datawizard` in `easystats`
- `Hmisc` package's `describe()`, or
- `summary()`

all of which can work nicely in an HTML presentation, but none of them fit well on a slide.

## Histogram of each quantity

:::{.callout-note}
I used `#| warning: false` in this code chunk to avoid warnings about missing values, like this one for `inc_imp`:

```
Warning: Removed 120 rows containing non-finite values
```
:::
```{r}
#| warning: false
#| echo: true
#| output-location: slide
p1 <- ggplot(smt, aes(x = bmi)) + 
    geom_histogram(fill = "navy", col = "white", bins = 20)
p2 <- ggplot(smt, aes(x = inc_imp)) + 
    geom_histogram(fill = "forestgreen", col = "white", bins = 20)
p3 <- ggplot(smt, aes(x = fruit_day)) + 
    geom_histogram(fill = "tomato", col = "white", bins = 20)
p4 <- ggplot(smt, aes(x = drinks_wk)) + 
    geom_histogram(fill = "royalblue", col = "white", bins = 20)

(p1 + p2) / (p3 + p4)
```

## Binary variables in raw `smt`

```{r}
#| echo: true
smt |> tabyl(female, exerany) |> adorn_title()
```

- `female` is based on biological sex (1 = female, 0 = male)
- `exerany` comes from a response to "During the past month, other than your regular job, did you participate in any physical activities or exercises such as running, calisthenics, golf, gardening, or walking for exercise?" (1 = yes, 0 = no, don't know and refused = missing)
- Any signs of trouble here?

## Multicategorical `genhealth` in raw `smt`

```{r}
#| echo: true
smt |> tabyl(genhealth)
```

- The variable is based on "Would you say that in general your health is ..." using the five specified categories (Excellent -> Poor), numbered for convenience after data collection.
- Don't know / not sure / refused treated as missing.
- How might we manage this variable?

## Changing the levels for `genhealth`

```{r}
#| echo: true
smt <- smt |>
    mutate(health = 
               fct_recode(genhealth,
                          E = "1_Excellent",
                          VG = "2_VeryGood",
                          G = "3_Good",
                          F = "4_Fair",
                          P = "5_Poor"),
           health = fct_relevel(health, "E", "VG", "G", "F", "P"))
```

Might want to run a sanity check here, just to be sure...

## Checking `health` vs. `genhealth`

```{r}
#| echo: true
smt |> tabyl(genhealth, health) |> adorn_title()
```

- OK. We've adjusted the order to something more sensible, retained the missing value, and we have much shorter labels.

## Multicategorical `race_eth` in raw `smt`

```{r}
#| echo: true
smt |> count(race_eth)
```

"Don't know", "Not sure", and "Refused" were treated as missing.

>- What is this variable actually about?
>- What is the most common thing people do here?

## What is the question you are asking?

Collapsing `race_eth` levels *might* be rational for *some* questions.

- We have lots of data from two categories, but only two.
- Systemic racism affects people of color in different ways across these categories, but also *within* them.

## Is combining race and Hispanic/Latinx ethnicity helpful?

It's hard to see the justice in collecting this information and not using it in as granular a form as possible, though this leaves some small sample sizes. There is no magic number for "too small a sample size."

- Most people identified themselves in one category.
- These data are not ordered, and (I'd argue) ordering them isn't helpful.
- Regression models are easier to interpret, though, if the "baseline" category is a common one.

## Resorting the factor for `race_eth`

Let's sort all five levels, from most observations to least...

```{r}
#| echo: true
smt <- smt |>
    mutate(race_eth = fct_infreq(race_eth))

smt |> tabyl(race_eth)
```

- Not a perfect solution, certainly, but we'll try it out.

## "Cleaned" Data and Missing Values

```{r}
#| echo: true
smt <- smt |>
    select(ID, bmi, inc_imp, fruit_day, drinks_wk, 
           female, exerany, health, race_eth)

miss_var_summary(smt)
```

## Single Imputation with `mice`

```{r}
#| echo: true
smt_im <- mice(smt, m = 1, seed = 20250121, print = FALSE) |>
  complete() |>
  tibble()
```

:::{.callout-note}

You may get a logged event for the ID variable expressed as a character, and that can be ignored.

:::

```{r}
#| echo: true
prop_miss_case(smt_im)
dim(smt_im)
```

## Saving the tidied data

Let's save both the unimputed and the imputed tidy data as R data sets.

```{r}
#| echo: true
write_rds(smt, "c03/data/smt.Rds")

write_rds(smt_im, "c03/data/smt_im.Rds")
```

To reload these files, we'll use `read_rds()`. 

- The main advantage here is that we've saved the whole R object, including all characteristics that we've added since the original download.
