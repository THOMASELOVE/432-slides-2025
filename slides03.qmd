---
title: "432 Class 03"
author: Thomas E. Love, Ph.D.
date: "2025-01-21"
format:
  revealjs: 
    theme: simple
    embed-resources: true
    self-contained: true
    slide-number: true
    footnotes-hover: true
    preview-links: auto
    date-format: iso
    logo: 432-2025-pic.png
    footer: "432 Class 03 | 2025-01-21 | <https://thomaselove.github.io/432-2025/>"
---

## Today's Agenda

- Fitting two-factor ANOVA/ANCOVA models with `lm`
    - Incorporating an interaction between factors
    - Incorporating a quantitative covariate
    - Using a quadratic polynomial fit
- Regression Diagnostics via `check_model()`
- Validating / evaluating results with `yardstick`

### Appendix

How the `c3im` data were created from `smart_ohio.csv`

## Today's R Setup

```{r}
#| echo: true
#| message: false
knitr::opts_chunk$set(comment = NA)

library(janitor)
library(naniar)
library(broom)
library(car)
library(gt)
library(mosaic)         ## for df_stats and favstats
library(mice)           ## imputation of missing data
library(patchwork)       
library(rms)            ## regression tools (Frank Harrell)
library(rsample)        ## data splitting
library(yardstick)      ## evaluating fits
library(easystats)
library(tidyverse)      

theme_set(theme_lucid()) 
```

# The `c3im` data

## The `c3im` data

- 894 subjects in Cleveland-Elyria with `bmi` and no history of diabetes (missing values singly imputed: assume MAR)
- All subjects have `hx_diabetes` (all 0), and are located in the `MMSA` labeled Cleveland-Elyria.
- See [Course Notes Chapter on BRFSS SMART data](https://thomaselove.github.io/432-notes/06-smart.html) for variable details
- Appendix provides details on data development.

## The Five Variables We'll Use Today
 
9 variables in the data but we'll use only these 5 today.

Variable | Description
:----: | --------------------------------------
`ID` | subject identifying code
`bmi` | (outcome) Body-Mass index in kg/m^2^.
`exerany` | any exercise in the past month: 1 = yes, 0 = no
`genhealth` | self-reported overall health (5 levels)
`fruit_day` | average fruit servings consumed per day

## Data Load

```{r}
#| echo: true
c3im <- read_rds("c03/data/c3im.Rds")
c3im
c3im |> n_miss()
identical(nrow(c3im), n_distinct(c3im$ID))
```

## Our covariate, `fruit_day` {.smaller}

Our main interest is in the factors `exerany` and `genhealth`.

Later, we'll adjust for the (quantitative) covariate `fruit_day`. Here, we'll be including the covariate to help account for some nuisance variation, rather than being deeply interested in the impact of `fruit_day` on `bmi`. 

A common approach, then, is centering the predictor (subtracting its mean) prior to including it.

```{r}
#| echo: true
c3im <- c3im |>
  mutate(fruit_c = fruit_day - mean(fruit_day))

df_stats(~ fruit_day + fruit_c, data = c3im) |> gt() |>
  fmt_number(columns = min:sd, decimals = 3) |>
  tab_options(table.font.size = 20)
```


## Splitting the Sample

We'll partition our data set using some tools from the `rsample` package, into:

- a training sample containing 75% of the data
- a testing sample containing the remaining 25%

```{r}
#| echo: true
set.seed(432)    ## for future replication

c3im_split <- initial_split(c3im, prop = 3/4)

train_c3im <- training(c3im_split)
test_c3im <- testing(c3im_split)

c(nrow(c3im), nrow(train_c3im), nrow(test_c3im))
```

# Building Models

## Models We'll Build Today

1. Predict `bmi` using `exer_any` and `genhealth` (both categorical)
    - without (and then with) an interaction between the predictors
2. Add in a (centered) quantitative covariate, `fruit_c`.
3. Incorporate `fruit_c` using a quadratic polynomial.

We'll fit all of these models with `lm`, and assess them in terms of first in-sample (training) fit and then out-of-sample (testing) performance.

## Consider transforming `bmi`?

```{r}
#| echo: true

m0 <- lm(bmi ~ exerany + health, data = train_c3im)
boxCox(m0)
```

## Should we transform `bmi`?

```{r}
#| echo: true
#| output-location: slides

p1 <- ggplot(train_c3im, aes(x = bmi)) + 
    geom_histogram(col = "navy", fill = "gold", bins = 20)

p2 <- ggplot(train_c3im, aes(x = 1/bmi)) + 
    geom_histogram(col = "navy", fill = "green", bins = 20)

p1 / p2
```

## Re-scaling the transformation

```{r}
#| echo: true
bind_rows( favstats(~ 1/bmi, data = train_c3im),
           favstats(~ 1000/bmi, data = train_c3im)) |>
  mutate(outcome = c("1/bmi", "1000/bmi")) |> 
  relocate(outcome) |>
  gt() |> fmt_number(columns = min:sd, decimals = 3) |> 
  tab_options(table.font.size = 24)
```

## Shape doesn't change

```{r}
p2 <- ggplot(train_c3im, aes(x = 1/bmi)) + 
  geom_histogram(col = "navy", fill = "green", bins = 20) +
  labs(title = "1/BMI")

p3 <- ggplot(train_c3im, aes(x = 1000/bmi)) +
  geom_histogram(col = "navy", fill = "green", bins = 20) + 
  labs(title = "1000/BMI")

p2 / p3
```

## Means by `exerany` and `health`

```{r}
#| echo: true
summaries_1 <- train_c3im |>
    group_by(exerany, health) |>
    summarise(n = n(), mean = mean(1000/bmi), stdev = sd(1000/bmi))
summaries_1 
```

## Code for Interaction Plot 

```{r}
#| echo: true
#| output-location: slide
ggplot(summaries_1, aes(x = health, y = mean, col = factor(exerany))) +
  geom_point(size = 2) +
  geom_line(aes(group = factor(exerany))) +
  scale_color_viridis_d(option = "C", end = 0.5) +
  labs(title = "Observed Means of 1000/BMI",
       subtitle = "by Exercise and Overall Health")
```

- Note the use of `factor` here since the `exerany` variable is in fact numeric, although it only takes the values 1 and 0.
    - Sometimes it's helpful to treat 1/0 as a factor, and sometimes not.
- Where is the evidence of serious non-parallelism (if any) in the plot (see next slide) that results from this code?

# Fitting a Two-Way ANOVA model for 1000/BMI

## Model `m1` without interaction

```{r}
#| echo: true
m1 <- lm(1000/bmi ~ exerany + health, data = train_c3im)
```

Using the `tidy()` function from `broom`:

```{r}
#| echo: true
tidy(m1, conf.int = TRUE, conf.level = 0.90) |> 
  gt() |> fmt_number(columns = estimate:conf.high, decimals = 3) |>
  tab_options(table.font.size = 24)
```

## Model Parameters for `m1`

```{r}
#| echo: true
model_parameters(m1, ci = 0.90) 
```

## Model Parameters for `m1` (with `gt()`)

Reformatting with `gt()`...

```{r}
#| echo: true
model_parameters(m1, ci = 0.90) |> 
  gt() |> fmt_number(columns = -c(CI, df_error), decimals = 3) |>
  tab_options(table.font.size = 20)
```

## How well does `m1` fit the training data?

```{r}
#| echo: true

model_performance(m1)
```

```{r}
#| echo: true
glance(m1) |> 
    select(r.squared, adj.r.squared, sigma, nobs, 
           df, df.residual, AIC, BIC) |> 
  gt() |> fmt_number(columns = r.squared:sigma, decimals = 3) |>
  fmt_number(columns = AIC:BIC, decimals = 1) |>
  tab_options(table.font.size = 24)
```

## Tidied ANOVA for `m1`

```{r}
#| echo: true
tidy(anova(m1)) |> gt() |> 
  fmt_number(columns = sumsq:statistic, decimals = 2) |>
  fmt_number(columns = p.value, decimals = 4) |>
  tab_options(table.font.size = 20)
```

## Interpreting `m1`

Name | `exerany` | `health` | predicted `1000/bmi`
-------- | :------: | :------: | ---------:
Harry | 0 | Excellent | 37.84
Sally   | 1 | Excellent | 37.84 + 1.85 = 39.69
Billy | 0 | Fair | 37.84 - 3.52 = 34.32
Meg | 1 | Fair | 37.84 + 1.85 - 3.52 = 36.17

- Effect of `exerany`?
- Effect of `health` = Fair instead of Excellent?

## Model Checks

We'll be checking assumptions related to:

- linearity
- homoscedasticity (constant variance)
- influential observations (outliers, leverage and influence)
- whether the residuals follow a Normal distribution
- collinearity (variance inflation factor)
- and a posterior predictive check of our predictions

## A Note about my approach

In your work, you'd just use:

```{r}
#| echo: true
#| eval: false

check_model(m1, detrend = FALSE)
```

with `#| fig-height: 9` at the start of the code chunk so that the plots are easier to read, but I need to do more here so the slides look nice...


## Checking model `m1` (*n* = 670)

```{r}
#| echo: true
check_model(m1, check = c("linearity", "homogeneity"))
```

## Checking model `m1` (*n* = 670)

```{r}
#| echo: true
check_model(m1, check = c("outliers", "qq"), detrend = FALSE)
```

## Checking model `m1` (*n* = 670)

```{r}
#| echo: true
check_model(m1, check = c("pp_check", "vif"))
```

# Fitting ANOVA model `m1int` including interaction

## Adding the interaction term to `m1`

```{r}
#| echo: true
m1int <- lm(1000/bmi ~ exerany * health, data = train_c3im)
```

- How do our models compare on fit to the training data?

```{r}
#| echo: true
bind_rows(glance(m1), glance(m1int)) |>
  mutate(mod = c("m1", "m1int")) |>
  select(mod, r.sq = r.squared, adj.r.sq = adj.r.squared, 
         sigma, nobs, df, df.res = df.residual, AIC, BIC) |> 
  gt() |> fmt_number(columns = r.sq:sigma, decimals = 3) |>
  fmt_number(columns = AIC:BIC, decimals = 1) |>
  tab_options(table.font.size = 20)
```

## ANOVA for the `m1int` model

```{r}
#| echo: true
tidy(anova(m1int)) |> gt() |> 
  fmt_number(columns = sumsq:statistic, decimals = 2) |>
  fmt_number(columns = p.value, decimals = 4) |>
  tab_options(table.font.size = 20)
```

## ANOVA test comparing `m1` to `m1int`

```{r}
#| echo: true
anova(m1, m1int)
```

## `m1int` coefficients

```{r}
#| echo: true
tidy(m1int, conf.int = TRUE, conf.level = 0.90) |>
  gt() |> fmt_number(columns = estimate:conf.high, decimals = 3) |>
  tab_options(table.font.size = 20)
```

## Interpreting the `m1int` model

Name | `exerany` | `health` | predicted `1000/bmi`
-------- | :------: | :------: | ---------:
Harry | 0 | Excellent | 36.95
Sally   | 1 | Excellent | 36.95 + 2.92 = 39.87
Billy | 0 | Fair | 36.95 - 5.24 = 31.71
Meg | 1 | Fair | 36.95 + 2.92 - 5.24 + 3.44 = 38.07

- How do we interpret effect sizes here? **It depends**.

## Interpreting the `m1int` model

- Effect of `exerany` on predicted `1000/bmi`?
    - If `health` = Excellent, effect is +2.92
    - If `health` = Fair, effect is (2.92 + 3.44) = +6.36
- Effect of `health` = Fair instead of Excellent?
    - If `exerany` = 0 (no), effect is -5.24
    - If `exerany` = 1 (yes), effect is (-5.24 + 3.44) = -1.80

## Checking model `m1int` (*n* = 670)

```{r}
#| echo: true
check_model(m1int, check = c("linearity", "homogeneity"))
```

## Checking model `m1int` (*n* = 670)

```{r}
#| echo: true
check_model(m1int, check = c("outliers", "qq"), detrend = FALSE)
```

## Checking model `m1int` (*n* = 670)

```{r}
#| echo: true
check_model(m1int, check = c("pp_check", "vif"))
```

# Incorporating a Covariate into our two-way ANOVA models

## Add `fruit_c` to `m1`

```{r}
#| echo: true
m2 <- lm(1000/bmi ~ fruit_c + exerany + health, data = train_c3im)
```

- How well does this model fit the training data?

```{r}
#| echo: true
bind_rows(glance(m1), glance(m2)) |>
  mutate(mod = c("m1", "m2")) |>
  select(mod, r.sq = r.squared, adj.r.sq = adj.r.squared, 
         sigma, df, df.res = df.residual, AIC, BIC) |> 
  gt() |> fmt_number(columns = r.sq:sigma, decimals = 3) |>
  fmt_number(columns = AIC:BIC, decimals = 1) |>
  tab_options(table.font.size = 20)
```

## ANOVA for the `m2` model

```{r}
#| echo: true
tidy(anova(m2)) |> gt() |> 
  fmt_number(columns = sumsq:statistic, decimals = 2) |>
  fmt_number(columns = p.value, decimals = 4) |>
  tab_options(table.font.size = 20)
```


## `m2` coefficients

```{r}
#| echo: true
tidy(m2, conf.int = TRUE, conf.level = 0.90) |>
  gt() |> fmt_number(columns = estimate:conf.high, decimals = 3) |>
  tab_options(table.font.size = 20)
```

## Checking model `m2` (*n* = 670)

```{r}
#| echo: true
check_model(m2, detrend = FALSE, check = c("pp_check", "qq"))
```


## Include the interaction term?

```{r}
#| echo: true
m2int <- lm(1000/bmi ~ fruit_c + exerany * health, 
          data = train_c3im)
```

### ANOVA for the `m2int` model

```{r}
#| echo: true
tidy(anova(m2int)) |> gt() |> 
  fmt_number(columns = sumsq:statistic, decimals = 2) |>
  fmt_number(columns = p.value, decimals = 4) |>
  tab_options(table.font.size = 20)
```

## `m2int` coefficients

```{r}
#| echo: true
tidy(m2int, conf.int = TRUE, conf.level = 0.90) |>
  gt() |> fmt_number(columns = estimate:conf.high, decimals = 3) |>
  tab_options(table.font.size = 18)
```

## ANOVA: Compare `m2` & `m2int`

```{r}
#| echo: true
anova(m2, m2int)
```

## Checking model `m2` (*n* = 670)

```{r}
#| echo: true
check_model(m2int, detrend = FALSE, check = c("pp_check", "qq"))
```

# Comparing Our Models

## Compare In-Sample Performance

```{r}
#| echo: true

plot(compare_performance(m1, m1int, m2, m2int))
```

## Which of the four models fits best?

In the **training** sample, we have...

```{r}
bind_rows(glance(m1), glance(m2), glance(m1int), glance(m2int)) |>
  mutate(mod = c("m1", "m2", "m1int", "m2int")) |>
  select(mod, r.sq = r.squared, adj.r.sq = adj.r.squared, 
         sigma, df, df.res = df.residual, AIC, BIC) |> 
  gt() |> fmt_number(columns = r.sq:sigma, decimals = 3) |>
  fmt_number(columns = AIC:BIC, decimals = 1) |>
  tab_options(table.font.size = 20)
```

- Adjusted $R^2$, $\sigma$ and AIC all improve as we move down from `m1` towards `m2_int`. BIC likes `m1` and `m2`.
- The training sample cannot judge between models accurately. Our models have already *seen* that data.




## What does `augment()` give us?

```{r}
#| echo: true

m1_test_aug <- augment(m1, newdata = test_c3im) |> 
  mutate(out = 1000/bmi)
m1_test_aug |> select(ID, bmi, out, .fitted, .resid, health, exerany) |>
  slice(198:202) |> gt() |> 
  fmt_number(columns = bmi:.resid, decimals = 2) |>
  tab_options(table.font.size = 20)
```

Here, `.fitted` = predicted `out` and `.resid` = `out` - `.fitted`.

## What to do?

Our models predict `1000/bmi`, but we want to assess predictions of `bmi`. How do we convert predicted `1000/bmi` to predicted `bmi`?

Note that 1000/(1000/`bmi`) = `bmi`, so we need

- 1000/`.fitted` for our predicted `bmi`, and
- observed `bmi` - predicted `bmi` for our residuals

## Adjusting `augment()` appropriately

```{r}
#| echo: true
m1_test_aug <- augment(m1, newdata = test_c3im) |> 
  mutate(bmi_fit = 1000/.fitted, bmi_res = bmi - bmi_fit)
m1_test_aug |> 
  select(ID, bmi, bmi_fit, bmi_res, health, exerany, .fitted, .resid) |>
  slice(198:202) |> gt() |> 
  fmt_number(columns = bmi:bmi_res, decimals = 2) |>
  fmt_number(columns = .fitted:.resid, decimals = 2) |>
  tab_options(table.font.size = 20)
```


## Augment all four models so far...

```{r}
#| echo: true
m1_test_aug <- augment(m1, newdata = test_c3im) |>
  mutate(bmi_fit = 1000/.fitted, bmi_res = bmi - bmi_fit)

m1int_test_aug <- augment(m1int, newdata = test_c3im) |>
  mutate(bmi_fit = 1000/.fitted, bmi_res = bmi - bmi_fit)

m2_test_aug <- augment(m2, newdata = test_c3im) |>
  mutate(bmi_fit = 1000/.fitted, bmi_res = bmi - bmi_fit)

m2int_test_aug <- augment(m2int, newdata = test_c3im) |>
  mutate(bmi_fit = 1000/.fitted, bmi_res = bmi - bmi_fit)
```

# Using the `yardstick` package

## The `yardstick` package

For each subject in the testing set, we will need:

- estimate = model's prediction of that subject's `bmi`
- truth = the `bmi` value observed for that subject

Calculate a summary of the predictions across the $n$ test subjects

## Summaries from `yardstick`

- $R^2$ = squared correlation of truth and estimate 
- `mae` = mean absolute error ...

$$
mae = \frac{1}{n} \sum{|truth - estimate|}
$$

- `rmse` = root mean squared error ...

$$
rmse = \sqrt{\frac{1}{n} \sum{(truth - estimate)^2}}
$$

## Testing Results (Validated $R^2$)

We can use the `yardstick` package and its `rsq()` function.

```{r}
#| echo: true
testing_r2 <- bind_rows(
    yardstick::rsq(m1_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rsq(m1int_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rsq(m2_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rsq(m2int_test_aug, truth = bmi, estimate = bmi_fit)) |>
    mutate(model = c("m1", "m1int", "m2", "m2int"))
testing_r2 |> 
  gt() |> fmt_number(.estimate, decimals = 3) |>
  tab_options(table.font.size = 20)
```


## Mean Absolute Error?

Consider the mean absolute prediction error ...

```{r}
#| echo: true
testing_mae <- bind_rows(
    yardstick::mae(m1_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::mae(m1int_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::mae(m2_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::mae(m2int_test_aug, truth = bmi, estimate = bmi_fit)) |>
    mutate(model = c("m1", "m1int", "m2", "m2int"))
testing_mae |> 
  gt() |> fmt_number(.estimate, decimals = 4) |>
  tab_options(table.font.size = 20)
```


## Root Mean Squared Error?

How about the square root of the mean squared prediction error, or RMSE?

```{r}
#| echo: true
testing_rmse <- bind_rows(
   yardstick::rmse(m1_test_aug, truth = bmi, estimate = bmi_fit),
   yardstick::rmse(m1int_test_aug, truth = bmi, estimate = bmi_fit),
   yardstick::rmse(m2_test_aug, truth = bmi, estimate = bmi_fit),
   yardstick::rmse(m2int_test_aug, truth = bmi, estimate = bmi_fit)) |>
   mutate(model = c("m1", "m1int", "m2", "m2int"))
testing_rmse |> 
  gt() |> fmt_number(.estimate, decimals = 3) |>
  tab_options(table.font.size = 20)
```

## Other `yardstick` summaries (1)

- `rsq_trad()` = defines $R^2$ using sums of squares. 
    - The `rsq()` measure we showed a few slides ago is a squared correlation coefficient guaranteed to be in (0, 1).
- `mape()` = mean absolute percentage error
- `mpe()` = mean percentage error

## Other `yardstick` summaries (2)

- `huber_loss()` = Huber loss (often used in robust regression), which is less sensitive to outliers than `rmse()`.
- `ccc()` = concordance correlation coefficient, which attempts to measure both consistency/correlation (like `rsq()`) and accuracy (like `rmse()`).

See [the yardstick home page](https://yardstick.tidymodels.org/index.html) for more details.

# Incorporating Non-Linearity into our models

## Polynomial Regression

A polynomial in the variable `x` of degree D is a linear combination of the powers of `x` up to D.

- Linear: $y = \beta_0 + \beta_1 x$
- Quadratic: $y = \beta_0 + \beta_1 x + \beta_2 x^2$
- Cubic: $y = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3$
- Quartic: $y = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \beta_4 x^4$

Fitting such a model creates a **polynomial regression**.

## Adding a polynomial in `fruit_c`

Can we predict `1000/bmi` with a polynomial in `fruit_c`?

```
lm(1000/bmi ~ fruit_c, data = train_c3im)
lm(1000/bmi ~ poly(fruit_c, 2), data = train_c3im)
lm(1000/bmi ~ poly(fruit_c, 3), data = train_c3im)
```

## Plotting the Polynomials

```{r}
#| echo: true
#| output-location: slide
p1 <- ggplot(train_c3im, aes(x = fruit_c, y = 1000/bmi)) +
    geom_point(alpha = 0.3) + 
    geom_smooth(formula = y ~ x, method = "lm", 
                col = "red", se = FALSE) + 
    labs(title = "Linear Fit")

p2 <- ggplot(train_c3im, aes(x = fruit_c, y = 1000/bmi)) +
    geom_point(alpha = 0.3) + 
    geom_smooth(formula = y ~ poly(x, 2), method = "lm",
                col = "blue", se = FALSE) +
    labs(title = "2nd order Polynomial")

p3 <- ggplot(train_c3im, aes(x = fruit_c, y = 1000/bmi)) +
    geom_point(alpha = 0.3) + 
    geom_smooth(formula = y ~ poly(x, 3), method = "lm",
                col = "purple", se = FALSE) +
    labs(title = "3rd order Polynomial")

p1 + p2 + p3
```



## Raw vs. Orthogonal Polynomials

Predict `1000/bmi` using `fruit_c` with a "raw polynomial of degree 2."

```{r}
#| echo: true
temp1 <- lm(1000/bmi ~ fruit_c + I(fruit_c^2), data = train_c3im)
temp1$coefficients
```

Predicted `1000/bmi` for `fruit_c = 0.5` is 

```
1000/bmi = 37.34842948 + 1.05552458 (fruit_c) - 0.09700152 (fruit_c^2)
         = 37.34842948 + 1.05552458 (0.5) - 0.09700152 (0.25)
         = 37.85194
```

## Does the raw polynomial match our expectations?

```{r}
#| echo: true
temp1 <- lm(1000/bmi ~ fruit_c + I(fruit_c^2), 
             data = train_c3im)

augment(temp1, newdata = tibble(fruit_c = 0.5)) |> 
  gt() |> tab_options(table.font.size = 20)
```

This matches our "by hand" calculation.

- But it turns out most regression models use *orthogonal* rather than raw polynomials...

## Fitting an Orthogonal Polynomial

Predict `1000/bmi` using `fruit_c` with an *orthogonal* polynomial of degree 2.

```{r}
#| echo: true
(temp2 <- lm(1000/bmi ~ poly(fruit_c,2), data = train_c3im))
```

This looks very different from our previous version of the model. What happens when we make a prediction, though?

## Orthogonal Polynomial Model Fit

In our raw polynomial model, our "by hand" and "using R" calculations each predicted `1000/bmi` for a subject with `fruit_c` = 0.5 to be 37.85194.

What happens with the orthogonal polynomial model `temp2`?

```{r}
#| echo: true
augment(temp2, newdata = data.frame(fruit_c = 0.5)) |> 
  gt() |> tab_options(table.font.size = 20)
```

- No change in the prediction.

## Fits of raw vs orthogonal polynomials

```{r}
#| echo: true
#| output-location: slide
temp1_aug <- augment(temp1, train_c3im)
temp2_aug <- augment(temp2, train_c3im)

p1 <- ggplot(temp1_aug, aes(x = fruit_c, y = 1000/bmi)) +
    geom_point(alpha = 0.3) +
    geom_line(aes(x = fruit_c, y = .fitted), col = "red", size = 2) +
    labs(title = "temp1: Raw fit, degree 2")

p2 <- ggplot(temp2_aug, aes(x = fruit_c, y = 1000/bmi)) +
    geom_point(alpha = 0.3) +
    geom_line(aes(x = fruit_c, y = .fitted), col = "blue", size = 2) +
    labs(title = "temp2: Orthogonal fit, degree 2")

p1 + p2 + 
    plot_annotation(title = "Comparing Two Methods of Fitting a Quadratic Polynomial")
```

- The two models are, in fact, identical.

## Why use orthogonal polynomials?

- The main reason is to avoid having to include powers of our predictor that are highly collinear. 
- Variance Inflation Factor assesses collinearity...

```{r}
#| echo: true
rms::vif(temp1)        ## from rms package
```

- Orthogonal polynomial terms are uncorrelated...

```{r}
#| echo: true
rms::vif(temp2)      
```


## Why orthogonal polynomials?

The tradeoff is that the raw polynomial is a lot easier to explain in terms of a single equation in the simplest case. 

:::{.callout-note}

Actually, we'll often use **splines** instead of polynomials, which are more flexible and require less maintenance, but at the cost of pretty much requiring you to focus on visualizing their predictions rather than their equations. We'll talk about splines later.

:::

## Adding a Second Order Polynomial

```{r}
#| echo: true
m3 <- lm(1000/bmi ~ poly(fruit_c,2) + exerany + health,
          data = train_c3im)
```

```{r}
#| echo: true
model_parameters(m3, ci = 0.9)
```


## m3 vs. m1 and m2

```{r}
bind_rows(glance(m1), glance(m2), glance(m3)) |>
  mutate(mod = c("m1", "m2", "m3")) |>
  select(mod, r.squared, adj.r.squared, sigma, 
         df, df.residual, nobs, AIC, BIC) |> 
  gt() |> fmt_number(columns = r.squared:adj.r.squared, decimals = 4) |>
  fmt_number(columns = sigma, decimals = 3) |>
  fmt_number(columns = AIC:BIC, decimals = 1) |>
  tab_options(table.font.size = 20)
```

```{r}
plot(compare_performance(m1, m2, m3))
```

## `m3` model check

```{r}
#| echo: true
check_model(m3, detrend = FALSE, check = c("pp_check", "qq"))
```

## Add in the interaction

```{r}
#| echo: true
m3int <- lm(1000/bmi ~ poly(fruit_c,2) + exerany * health,
          data = train_c3im)

model_parameters(m3int, ci = 0.90)
```

## Comparison of interaction models

```{r}
bind_rows(glance(m1int), glance(m2int), glance(m3int)) |>
  mutate(mod = c("m1int", "m2int", "m3int")) |>
  select(mod, r.squared, adj.r.squared, sigma, 
         df, df.residual, nobs, AIC, BIC) |> 
  gt() |> fmt_number(columns = r.squared:adj.r.squared, decimals = 4) |>
  fmt_number(columns = sigma, decimals = 3) |>
  fmt_number(columns = AIC:BIC, decimals = 1) |>
  tab_options(table.font.size = 20)
```


```{r}
plot(compare_performance(m1int, m2int, m3int))
```

## `m3int` model check

```{r}
#| echo: true
check_model(m3int, detrend = FALSE, check = c("pp_check", "qq"))
```

## Testing Sample for `m3` and `m3int`?

```{r}
#| echo: true
m3_test_aug <- augment(m3, newdata = test_c3im) |>
  mutate(bmi_fit = 1000/.fitted, bmi_res = bmi - bmi_fit)
m3int_test_aug <- augment(m3int, newdata = test_c3im) |>
  mutate(bmi_fit = 1000/.fitted, bmi_res = bmi - bmi_fit)

testing_r2 <- bind_rows(
    yardstick::rsq(m1_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rsq(m2_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rsq(m3_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rsq(m1int_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rsq(m2int_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rsq(m3int_test_aug, truth = bmi, estimate = bmi_fit)) |>
    mutate(mod = c("m1", "m2", "m3", "m1int", "m2int", "m3int"))
```

- I've hidden my calculations for RMSE and MAE here.

```{r}
testing_rmse <- bind_rows(
    yardstick::rmse(m1_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rmse(m2_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rmse(m3_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rmse(m1int_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rmse(m2int_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::rmse(m3int_test_aug, truth = bmi, estimate = bmi_fit)) |>
    mutate(mod = c("m1", "m2", "m3", "m1int",
                     "m2int", "m3int"))

testing_mae <- bind_rows(
    yardstick::mae(m1_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::mae(m2_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::mae(m3_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::mae(m1int_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::mae(m2int_test_aug, truth = bmi, estimate = bmi_fit),
    yardstick::mae(m3int_test_aug, truth = bmi, estimate = bmi_fit)) |>
    mutate(mod = c("m1", "m2", "m3", "m1int",
                     "m2int", "m3int"))
```

## Test Results for all six models

```{r}
#| echo: true
bind_cols(testing_r2 |> select(mod, rsquare = .estimate), 
          testing_rmse |> select(rmse = .estimate),
          testing_mae |> select(mae = .estimate)) |> 
  mutate(elements = c("exerany + health", "add fruit_c", "add polynomial", "m1 + interaction", "m2 + interaction", "m3 + interaction")) |>
  gt() |> fmt_number(columns = rsquare:mae, decimals = 4) |>
  tab_options(table.font.size = 20)
```

- Did the polynomial in `m3` and `m3int` improve predictions?

## What's Next?

Basics of logistic regression fitting and evaluation

# Appendix

## Creating Today's Data Set

```{r}
#| echo: true
#| message: false
url1 <- "https://raw.githubusercontent.com/THOMASELOVE/432-data/master/data/smart_ohio.csv"

smart_ohio <- read_csv(url1)

c3 <- smart_ohio |>
    filter(hx_diabetes == 0, mmsa == "Cleveland-Elyria",
           complete.cases(bmi)) |>
    select(bmi, inc_imp, fruit_day, drinks_wk, 
           female, exerany, genhealth, race_eth, 
           hx_diabetes, mmsa, SEQNO) |>            
    mutate(across(where(is.character), as_factor)) |>
    mutate(ID = as.character(SEQNO - 2017000000)) |>
    relocate(ID)
```

## Codebook for useful `c3` variables (1)

- 894 subjects in Cleveland-Elyria with `bmi` and no history of diabetes

Variable | Description
:----: | --------------------------------------
`bmi` | (outcome) Body-Mass index in kg/m^2^.
`inc_imp` | income (imputed from grouped values) in $
`fruit_day` | average fruit servings consumed per day
`drinks_wk` | average weekly alcoholic drinks consumed
`female` | sex: 1 = female, 0 = male

## Codebook for useful `c3` variables (2)

- 894 subjects in Cleveland-Elyria without diabetes

Variable | Description
:----: | --------------------------------------
`exerany` | any exercise in past month: 1 = yes, 0 = no
`genhealth` | self-reported overall health (5 levels)
`race_eth` | race and Hispanic/Latinx ethnicity (5 levels)

- plus `ID`, `SEQNO`, `hx_diabetes` (all 0), `MMSA`
- See [Course Notes Chapter 6](https://thomaselove.github.io/432-notes/smart.html) on BRFSS SMART data

## Basic Data Summaries

Available approaches include:

- `data_codebook()` from `datawizard` in `easystats`
- `Hmisc` package's `describe()`, or
- `summary()`

all of which can work nicely in an HTML presentation, but none of them fit well on a slide.

## Histogram of each quantity

:::{.callout-note}
I used `#| warning: false` in this code chunk to avoid warnings about missing values, like this one for `inc_imp`:

```
Warning: Removed 120 rows containing non-finite values
```
:::
```{r}
#| warning: false
#| echo: true
#| output-location: slide
p1 <- ggplot(c3, aes(x = bmi)) + 
    geom_histogram(fill = "navy", col = "white", bins = 20)
p2 <- ggplot(c3, aes(x = inc_imp)) + 
    geom_histogram(fill = "forestgreen", col = "white", bins = 20)
p3 <- ggplot(c3, aes(x = fruit_day)) + 
    geom_histogram(fill = "tomato", col = "white", bins = 20)
p4 <- ggplot(c3, aes(x = drinks_wk)) + 
    geom_histogram(fill = "royalblue", col = "white", bins = 20)

(p1 + p2) / (p3 + p4)
```

## Binary variables in raw `c3`

```{r}
#| echo: true
c3 |> tabyl(female, exerany) |> adorn_title()
```

- `female` is based on biological sex (1 = female, 0 = male)
- `exerany` comes from a response to "During the past month, other than your regular job, did you participate in any physical activities or exercises such as running, calisthenics, golf, gardening, or walking for exercise?" (1 = yes, 0 = no, don't know and refused = missing)
- Any signs of trouble here?

## Multicategorical `genhealth` in raw `c3`

```{r}
#| echo: true
c3 |> tabyl(genhealth)
```

- The variable is based on "Would you say that in general your health is ..." using the five specified categories (Excellent -> Poor), numbered for convenience after data collection.
- Don't know / not sure / refused treated as missing.
- How might we manage this variable?

## Changing the levels for `genhealth`

```{r}
#| echo: true
c3 <- c3 |>
    mutate(health = 
               fct_recode(genhealth,
                          E = "1_Excellent",
                          VG = "2_VeryGood",
                          G = "3_Good",
                          F = "4_Fair",
                          P = "5_Poor"))
```

Might want to run a sanity check here, just to be sure...

## Checking `health` vs. `genhealth` in `c3`

```{r}
#| echo: true
c3 |> tabyl(genhealth, health) |> adorn_title()
```

- OK. We've preserved the order and we have much shorter labels. Sometimes, that's helpful.

## Multicategorical `race_eth` in raw `c3`

```{r}
#| echo: true
c3 |> count(race_eth)
```

"Don't know", "Not sure", and "Refused" were treated as missing.

>- What is this variable actually about?
>- What is the most common thing people do here?

## What is the question you are asking?

Collapsing `race_eth` levels *might* be rational for *some* questions.

- We have lots of data from two categories, but only two.
- Systemic racism affects people of color in different ways across these categories, but also *within* them.

## Is combining race and Hispanic/Latinx ethnicity helpful?

It's hard to see the justice in collecting this information and not using it in as granular a form as possible, though this leaves some small sample sizes. There is no magic number for "too small a sample size."

- Most people identified themselves in one category.
- These data are not ordered, and (I'd argue) ordering them isn't helpful.
- Regression models are easier to interpret, though, if the "baseline" category is a common one.

## Resorting the factor for `race_eth`

Let's sort all five levels, from most observations to least...

```{r}
#| echo: true
c3 <- c3 |>
    mutate(race_eth = fct_infreq(race_eth))

c3 |> tabyl(race_eth)
```

- Not a perfect solution, certainly, but we'll try it out.

## "Cleaned" Data and Missing Values

```{r}
#| echo: true
c3 <- c3 |>
    select(ID, bmi, inc_imp, fruit_day, drinks_wk, 
           female, exerany, health, race_eth)

miss_var_summary(c3)
```

## Single Imputation with `mice`

```{r}
#| echo: true
c3im <- mice(c3, m = 1, seed = 20250121, print = FALSE) |>
  complete() |>
  tibble()
```

:::{.callout-note}

You may get a logged event for the ID variable expressed as a character, and that can be ignored.

:::

```{r}
#| echo: true
prop_miss_case(c3im)
dim(c3im)
```

## Saving the tidied data

Let's save both the unimputed and the imputed tidy data as R data sets.

```{r}
#| echo: true
write_rds(c3, "c03/data/c3.Rds")

write_rds(c3im, "c03/data/c3im.Rds")
```

To reload these files, we'll use `read_rds()`. 

- The main advantage here is that we've saved the whole R object, including all characteristics that we've added since the original download.
